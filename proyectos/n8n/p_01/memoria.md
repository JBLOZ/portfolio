
### Introducci√≥n al Proyecto: Bot de An√°lisis de Sentimiento Burs√°til

En un mundo financiero cada vez m√°s din√°mico y sobrecargado de informaci√≥n, tomar decisiones de inversi√≥n √°giles e informadas es un desaf√≠o constante. Los inversores, tanto novatos como experimentados, se enfrentan al reto de procesar grandes vol√∫menes de noticias, informes y opiniones para evaluar el sentimiento del mercado sobre un activo financiero. Este proceso no solo consume mucho tiempo, sino que tambi√©n requiere un an√°lisis complejo para extraer conclusiones pr√°cticas.

Para abordar este problema, hemos desarrollado una soluci√≥n innovadora: un **asistente conversacional inteligente a trav√©s de un bot de Telegram**, dise√±ado para realizar an√°lisis de sentimiento de mercado para cualquier acci√≥n o ETF bajo demanda.

Nuestro proyecto nace de la necesidad de simplificar y automatizar el acceso a inteligencia de mercado. El objetivo principal es proporcionar a cualquier usuario una herramienta accesible desde su m√≥vil que, con un simple comando, sea capaz de:
1.  **Recopilar las noticias m√°s recientes** y relevantes sobre un activo financiero espec√≠fico.
2.  **Utilizar un Modelo de Lenguaje Avanzado (LLM)** para analizar esta informaci√≥n y determinar el sentimiento general del mercado.
3.  **Generar una recomendaci√≥n de inversi√≥n clara y concisa** a medio plazo, categorizada en acciones como compra fuerte, compra, mantener, vender o venta fuerte.

Para lograrlo, hemos dise√±ado y construido una arquitectura robusta que integra m√∫ltiples tecnolog√≠as. Utilizando **n8n** como plataforma central de automatizaci√≥n para orquestar el flujo de trabajo, **Docker** para crear el entorno de ejecuci√≥n, y un t√∫nel de **Cloudflare** para exponer nuestro servicio local a Internet de forma segura y asi poder permitir la entrada de mensajes mediante nuestro bot de telegram.

Este proyecto no solo resuelve un problema real, sino que tambi√©n sirve como una demostraci√≥n pr√°ctica de c√≥mo la combinaci√≥n de la automatizaci√≥n de flujos de trabajo, la inteligencia artificial conversacional y la infraestructura nos permite crear potentes aplicaciones con recursos limitados. A continuaci√≥n, explicaremos en detalle cada uno de los pasos que hemos seguido para dar vida a este bot, desde la configuraci√≥n del entorno hasta el dise√±o del flujo de inteligencia.

Claro, aqu√≠ tienes una propuesta para la introducci√≥n de tu seminario. He estructurado el texto para que sea claro, profesional y capte la atenci√≥n, explicando el prop√≥sito y la relevancia del proyecto desde el primer momento.

***

### Configuraci√≥n del T√∫nel y Scripts de Inicio

Para que nuestro bot de Telegram pueda recibir y procesar mensajes en tiempo real, es fundamental exponer el servidor local de n8n a Internet, ya que Telegram requiere una URL p√∫blica y accesible para configurar el webhook del trigger. Sin esta exposici√≥n, el trigger de Telegram no podr√≠a funcionar, ya que n8n opera por defecto en localhost:5678, un puerto interno no visible desde fuera. Elegimos Cloudflare Tunnel (cloudflared) por su simplicidad y gratuidad para entornos de desarrollo, aunque sus URLs generadas no son est√°ticas y cambian en cada ejecuci√≥n, lo que impide hardcodearlas directamente en la configuraci√≥n de n8n.

El desaf√≠o principal radica en esta variabilidad: si intent√°ramos definir una URL fija en el nodo de Telegram o en el docker-compose.yml, el webhook fallar√≠a al reiniciar el servicio. Por ello, optamos por un enfoque din√°mico basado en variables de entorno (.env), que permite inyectar la URL generada autom√°ticamente en el contenedor de n8n sin intervenci√≥n manual cada vez. Este m√©todo asegura que el trigger de Telegram apunte siempre a la URL correcta, usando variables como WEBHOOK_URL, N8N_HOST y TUNNEL_URL para configurar el protocolo HTTPS y el host externo.

#### Paso 1: Instalaci√≥n y Preparaci√≥n de Cloudflare Tunnel
Primero, instalamos cloudflared en nuestro sistema operativo (en este caso, Linux o WSL para compatibilidad con Docker). Este herramienta crea un t√∫nel seguro desde nuestro puerto local (5678) hacia una URL temporal en el dominio trycloudflare.com, sin necesidad de cuenta ni configuraci√≥n compleja. El comando base para iniciarlo es `cloudflared tunnel --url http://localhost:5678`, que genera una salida como "https://xxxx.trycloudflare.com" y la registra en un log para su captura posterior. Este t√∫nel enruta el tr√°fico entrante de Telegram directamente a n8n, manteniendo la seguridad al no exponer puertos directamente en el firewall.

#### Paso 2: Creaci√≥n del Script de Inicio (start-n8n.sh)
Para automatizar todo el proceso, creamos el script start-n8n.sh, que sigue un orden espec√≠fico y secuencial para garantizar la integraci√≥n sin errores. El script comienza deteniendo cualquier instancia previa de cloudflared o Docker para evitar conflictos: `pkill cloudflared 2>/dev/null` y `docker-compose down 2>/dev/null`. Luego, lanza cloudflared en segundo plano con redirecci√≥n de salida a un archivo tunnel.log: `cloudflared tunnel --url http://localhost:5678 > tunnel.log 2>&1 &`, capturando el PID para control posterior.

A continuaci√≥n, el script espera hasta 30 segundos para que se genere la URL, monitoreando el log con un bucle: `grep -oP 'https://[a-zA-Z0-9-]+\.trycloudflare\.com' tunnel.log | head -1`.Una vez extra√≠da la URL (por ejemplo, https://offline-argued-drops.trycloudflare.com), la valida y la almacena en una variable TUNNEL_URL. Si no se obtiene en el tiempo l√≠mite, el script falla con un error y mata el proceso de cloudflared. Este paso es cr√≠tico porque sin la URL din√°mica, el webhook de Telegram no se configurar√≠a correctamente en n8n.

#### Paso 3: Actualizaci√≥n de Variables de Entorno (.env)
Con la URL en mano, el script actualiza el archivo .env, que sirve como fuente de variables para docker-compose.yml. Genera o sobrescribe el .env con contenido como:
- WEBHOOK_URL=${TUNNEL_URL}
- N8N_HOST=${TUNNEL_URL} (adaptado para HTTPS)
- TUNNEL_URL=${TUNNEL_URL}

Esto inyecta la URL en el entorno de n8n, permitiendo que el nodo de Telegram use autom√°ticamente WEBHOOK_URL como endpoint p√∫blico. El script muestra el contenido del .env para verificaci√≥n antes de proceder. De esta forma, evitamos editar manualmente el .env cada reinicio, haciendo el despliegue reproducible con un solo comando: `./start-n8n.sh`.

#### Paso 4: Lanzamiento del Contenedor de n8n
Finalmente, con el .env actualizado, el script ejecuta `docker-compose up -d`, iniciando el contenedor de n8n con las variables cargadas. El docker-compose.yml define el servicio n8n con puertos expuestos en 5678, vol√∫menes para persistencia de datos (/home/node/.n8n), y variables como N8N_PROTOCOL=https y N8N_EDITOR_BASE_URL=${TUNNEL_URL} para alinear la interfaz web y los webhooks. Una vez arriba, n8n configura internamente el webhook de Telegram apuntando a la URL del t√∫nel, completando el ciclo de exposici√≥n. Para detener todo, usamos un script complementario stop-n8n.sh que hace down en Docker y mata cloudflared, limpiando logs opcionalmente.

Esta configuraci√≥n no solo resuelve la exposici√≥n din√°mica, sino que tambi√©n mantiene el proyecto portable y escalable, ideal para demostraciones como esta. En la siguiente secci√≥n, detallaremos la creaci√≥n del bot en Telegram y su integraci√≥n en el workflow de n8n.


### Creaci√≥n del Bot de Telegram e Integraci√≥n del Trigger

Una vez configurado el t√∫nel para exponer n8n a Internet, el siguiente paso esencial es crear el bot en Telegram y conectarlo al workflow mediante el nodo de trigger de Telegram, que act√∫a como punto de entrada para recibir mensajes del usuario. Este trigger se basa en la API de Telegram Bot, que requiere un token de autenticaci√≥n para configurar un webhook que env√≠e actualizaciones de mensajes a nuestra URL p√∫blica (la generada por cloudflared). Sin esta integraci√≥n, el bot no podr√≠a interactuar con el flujo de n8n, ya que Telegram solo notifica a endpoints accesibles externamente.[1]

#### Paso 1: Creaci√≥n del Bot con BotFather
Para iniciar, abrimos Telegram y buscamos el usuario oficial @BotFather, que es la herramienta de Telegram para gestionar bots. Enviamos el comando `/newbot` seguido del nombre del bot (por ejemplo, "Stock Market Analytics Bot") y un username √∫nico terminando en "bot" (como @stock_market_analytics_bot), que debe ser p√∫blico y accesible para todos los usuarios. BotFather responde confirmando la creaci√≥n y proporcionando un **token de API** en formato `123456789:ABCDEF...`, que act√∫a como clave secreta para autenticar todas las peticiones del bot. Este token no debe compartirse p√∫blicamente, ya que otorga control total sobre el bot, incluyendo la capacidad de enviar y recibir mensajes.

#### Paso 2: Configuraci√≥n del Nodo de Trigger en n8n
Con el token en mano, accedemos a la interfaz de n8n (v√≠a la URL del t√∫nel) y creamos un nuevo workflow, arrastrando el nodo **Telegram Trigger** al canvas. En las credenciales del nodo, seleccionamos "Create New" para la autenticaci√≥n de Telegram, ingresando el token de API obtenido de BotFather y configurando el tipo como "Bot Token Authentication". El nodo tambi√©n requiere la URL del webhook, que se resuelve autom√°ticamente usando la variable de entorno WEBHOOK_URL del .env (injected v√≠a docker-compose), apuntando a `https://[t√∫nel].trycloudflare.com/webhook/[workflow-id]`, donde n8n maneja la ruta interna para actualizaciones. Al activar el workflow, n8n registra el webhook con la API de Telegram, confirmando que recibir√° notificaciones push para cada mensaje enviado al bot. Esto asegura que el trigger se active solo para nuestro bot, filtrando interacciones irrelevantes por defecto.[1]

#### Paso 3: Estructura del Mensaje Entrante y Preparaci√≥n para el Flujo
Cuando un usuario env√≠a un mensaje al bot, como `/analysis sp500`, el trigger de Telegram recibe un JSON estructurado con la actualizaci√≥n completa del mensaje, que incluye metadatos del usuario y el chat para contextualizar la interacci√≥n. La estructura t√≠pica es un array de objetos con campos como `update_id` (identificador √∫nico de la actualizaci√≥n), `message` (detalles del mensaje), que contiene `message_id`, `from` (informaci√≥n del emisor con `id` num√©rico), `chat` (detalles del chat con el mismo `id`), `date` (timestamp), `text` (contenido del mensaje, e.g., "/analysis sp500") y `entities` (anotaciones como comandos de bot). Por ejemplo, un mensaje de prueba genera algo como:

```
[
  {
    "update_id": 177484711,
    "message": {
      "message_id": 20,
      "from": {
        "id": 1065676350,
        "is_bot": false,
        "first_name": "Jordi",
        "last_name": "Blasco Lozano",
        "username": "jbloz",
        "language_code": "es"
      },
      "chat": {
        "id": 1065676350,
        "first_name": "Jordi",
        "last_name": "Blasco Lozano",
        "username": "jbloz",
        "type": "private"
      },
      "date": 1761410615,
      "text": "/analysis sp500",
      "entities": [
        {
          "offset": 0,
          "length": 9,
          "type": "bot_command"
        }
      ]
    }
  }
]
```

Este formato detallado es √∫til para tracking, pero para nuestro flujo de an√°lisis de sentimiento, necesitamos simplificarlo extrayendo solo los elementos esenciales: el texto despu√©s del comando (e.g., "sp500") y el ID del usuario (e.g., 1065676350) para respuestas posteriores. Por lo tanto, transformamos el JSON entrante en una estructura minimalista como:

```
[
  {
    "text": "sp500",
    "id": 1065676350
  }
]
```

Esta reformateaci√≥n se logra en los nodos subsiguientes (filtro y c√≥digo JavaScript), eliminando ruido como nombres, timestamps y entidades, para pasar datos limpios al resto del workflow sin sobrecargar el procesamiento. De esta manera, el trigger inicializa el flujo de forma eficiente, preparando el terreno para la validaci√≥n y extracci√≥n de comandos espec√≠ficos como `/analysis`.

En la pr√≥xima secci√≥n, detallaremos c√≥mo filtramos mensajes irrelevantes y refinamos el texto extra√≠do mediante nodos de c√≥digo.

### Transformaci√≥n y filtrado de los datos de entrada: Nodos Filter y JavaScript en n8n

Una vez que el trigger de Telegram recibe los mensajes enviados al bot, el siguiente paso en el workflow de n8n es limpiar y transformar los datos para quedarnos solo con la informaci√≥n relevante para nuestro an√°lisis burs√°til. El objetivo aqu√≠ es filtrar solo los mensajes que contengan el comando `/analysis` y extraer el texto posterior al comando (el ticker o nombre del activo) junto al identificador de usuario para personalizar las respuestas en el resto del flujo.[1][3]

#### Paso 1: Nodo de Filter

El nodo **Filter** funciona como una puerta de acceso, permitiendo √∫nicamente los mensajes que cumplen una condici√≥n clave: que el mensaje incluya la palabra `/analysis`. As√≠, si un usuario escribe cualquier otro texto o comando, el flujo lo descartar√° autom√°ticamente y no avanzar√° a las siguientes etapas. Esta l√≥gica reduce ruido y asegura que solo procesamos peticiones v√°lidas y estructuradas para el an√°lisis del sentimiento de mercado.[2][1]

- **Configuraci√≥n**: 
  - Campo a filtrar: `message.text` (dentro del JSON recibido).
  - Condici√≥n: contiene `/analysis`.
  - Acci√≥n: si pasa el filtro, el mensaje sigue el flujo; si no, se descarta.

#### Paso 2: Nodo Code (JavaScript)

El nodo **Code** o **Code in JavaScript** es donde transformamos el mensaje filtrado en un formato sencillo y funcional para el resto del workflow. El bloque de c√≥digo que has incluido cumple tres funciones principales:

- Toma el texto completo del mensaje (`fullText`) y el identificador del usuario (`ID`).
- Localiza el comando `/analysis` y extrae √∫nicamente el texto que viene detr√°s (lo que el usuario quiere analizar: un ticker, √≠ndice, etc.).
- Devuelve un objeto JSON minimalista con el formato exactamente necesario para la API siguiente: el `text` limpio y el `id` para enviar la respuesta al usuario correcto.

```javascript
const fullText = $input.item.json.message.text;
const ID = $input.item.json.message.from.id;
const command = "/analysis ";

// Extrae todo lo que viene despu√©s de /analysis
const textAfterCommand = fullText.includes(command) 
  ? fullText.substring(fullText.indexOf(command) + command.length).trim()
  : fullText;

return {
  json: {
    text: textAfterCommand,
    id: ID
  }
};
```

Gracias a esto, transformamos un mensaje de entrada complejo, como el que hemos visto en el paso anterior en una salida simple y limpia como esta:

```
[
  {
    "text": "sp500",
    "id": 1065676350
  }
]
```

Esto prepara el mensaje para ser enviado a la API de an√°lisis de sentimiento o cualquier otro m√≥dulo de procesamiento posterior, facilitando al m√°ximo la integraci√≥n y manteniendo limpio el flujo de trabajo en n8n.


### Paso siguiente: HTTP Request para buscar noticias con Perplexity API

Una vez que hemos procesado el mensaje del usuario para obtener √∫nicamente el texto relevante (el ticker o nombre del activo financiero), el siguiente paso del workflow consiste en consultar la API de Perplexity para recopilar las noticias m√°s recientes sobre ese activo. Esta b√∫squeda es fundamental para que el LLM realice el an√°lisis de sentimiento con informaci√≥n actualizada y relevante.

#### Perplexity, subscripci√≥n y API
Perplexity ofrece varias maneras de acceder a su API Pro, incluyendo un periodo de prueba de 12 meses si asocias una cuenta de PayPal, as√≠ como promociones puntuales para ciertas cuentas o estudiantes. En nuestro caso, disponemos de una suscripci√≥n Pro, que nos da acceso prioritario tanto a modelos avanzados como a la propia API. Esta suscripci√≥n incluye **5 ‚Ç¨ de cr√©dito API cada mes**, suficiente para mantener proyectos ligeros y pruebas recurrentes.

#### Acceso a la API de b√∫squeda
Con la suscripci√≥n Pro, tenemos acceso directo a la API, incluida la funci√≥n m√°s potente: la **API de b√∫squeda avanzada**. La documentaci√≥n oficial de Perplexity proporciona un ejemplo de integraci√≥n r√°pida mediante cURL (que podemos copiar y pegar al m√≥dulo de HTTP Request en n8n), autenticando cada llamada con nuestra clave personal. All√≠ mismo se detallan par√°metros de uso como el l√≠mite de resultados o el m√°ximo de tokens por noticia.

#### Ejemplo pr√°ctico de la integraci√≥n en n8n
Creamos un m√≥dulo HTTP Request justo despu√©s del bloque de JavaScript, usando estos ajustes:
- **URL:** `https://api.perplexity.ai/search`
- **M√©todo:** POST
- **Autenticaci√≥n:** Bearer Token (clave API de Perplexity)
- **Cuerpo (JSON):**
  ```json
  {
    "query": [
        "Last news about {{ $json.text }}",
        "{{ $json.text }} financial asset forecasts",
        "{{ $json.text }} financial asset last results"
    ],
    "max_results": 8
  }
  ```
Aqu√≠, `{{ $json.text }}` toma el ticker del paso anterior para personalizar la b√∫squeda. Para enriquecer los resultados, no nos limitamos a una sola consulta, sino que realizamos tres b√∫squedas simult√°neas sobre el mismo activo, solicitando noticias recientes, previsiones y los √∫ltimos resultados financieros. Esto proporciona un contexto mucho m√°s rico para el an√°lisis posterior.



---
### Formateo de Noticias y Preparaci√≥n para el An√°lisis (Code in JavaScript4)

Tras la llamada exitosa a la API de Perplexity (`HTTP Request1`), el workflow recibe un objeto JSON complejo que contiene una lista de noticias. Esta estructura, aunque rica en datos (con URLs, snippets, metadatos, etc.), no es un formato √≥ptimo para ser analizada directamente por un Modelo de Lenguaje (LLM). Para maximizar la precisi√≥n del an√°lisis y minimizar el consumo de tokens, es crucial "limpiar" y "condensar" esta informaci√≥n.

Esta tarea la realiza el nodo **Code in JavaScript4**. Su funci√≥n es iterar sobre el array de resultados de la b√∫squeda y concatenar la informaci√≥n esencial de cada noticia (como el t√≠tulo y el resumen o snippet) en un √∫nico bloque de texto plano. Este bloque de texto se formatea de manera legible, separando cada noticia para que el LLM pueda distinguirlas.

Adem√°s, este nodo inicializa un contador de reintentos (`retry_count: 0`), que ser√° clave para la l√≥gica de correcci√≥n que veremos m√°s adelante.

El resultado es un objeto JSON que contiene el `text` (nombre del activo), las `noticias` (el texto plano con toda la informaci√≥n) y el `retry_count`, sirviendo como la √∫nica "fuente de verdad" para los siguientes pasos de an√°lisis.

---
### Arquitectura de "Actor-Cr√≠tico": El Proceso de An√°lisis y Revisi√≥n

Para asegurar una alta fiabilidad en la respuesta y evitar las "alucinaciones" (respuestas incorrectas o inventadas) de la IA, implementamos una arquitectura avanzada de dos agentes conocida como **Actor-Cr√≠tico**. En lugar de confiar en un solo agente, uno genera el an√°lisis (el "Actor") y un segundo agente, m√°s estricto, lo revisa (el "Cr√≠tico").

#### Paso 1: El Actor - `AI Agent2` (Analista)

El primer agente, **`AI Agent2`**, act√∫a como el "Analista". Recibe el contexto de noticias formateado del nodo anterior. Su *prompt* (instrucci√≥n) le ordena realizar el an√°lisis completo y responder **√∫nicamente** con un formato de texto estricto que hemos definido:

```
Compra: [X]%
Mantener: [Y]%
Vender: [Z]%
Expectativa: [Alcista o Bajista]
Resumen: [Un resumen de un p√°rrafo de las noticias...]
```
Este formato simple basado en texto es f√°cil de generar para el modelo, pero a√∫n puede contener errores. La salida de este nodo es un √∫nico *string* de texto.

#### Paso 2: El Cr√≠tico - `AI Agent3` (Revisor)

Aqu√≠ es donde entra el control de calidad. El segundo agente, **`AI Agent3`**, act√∫a como el "Revisor". Este nodo recibe dos entradas cruciales:
1.  El **contexto de noticias original** (del nodo `Code in JavaScript4`).
2.  El **an√°lisis en texto** generado por el primer agente (la salida de `AI Agent2`).

La tarea del Revisor no es generar un an√°lisis, sino **juzgar** el an√°lisis del Actor. Su *prompt* le instruye a comparar el resumen y los porcentajes con las noticias originales y determinar si el an√°lisis est√° 100% justificado por ellas.

Para que su decisi√≥n sea utilizable por el workflow, forzamos su salida a un simple "True" o "False".

---
### Flujo Condicional: El Bucle de Correcci√≥n y Fusi√≥n

La salida del Revisor nos permite crear un flujo condicional para simular un "bucle de re-intento".

#### Paso 1: El Nodo `If1`

Este nodo lee la salida del `AI Agent3` (Revisor). Su condici√≥n es si la salida contiene "True" y si el an√°lisis del `AI Agent2` contiene las palabras clave esperadas ("Compra:", "Mantener:", etc.). Esto crea dos ramas:
* **Rama "True" (√âxito):** El an√°lisis es bueno y puede continuar.
* **Rama "False" (Error):** El an√°lisis es malo o incompleto y necesita ser rehecho.

#### Paso 2: La Rama "False" (Re-intento del Actor)

Esta rama es la clave de nuestra l√≥gica de "loop". Cuando el an√°lisis es `false`, el flujo se dirige al nodo `Code Increment Retry`, que aumenta en uno el contador de reintentos. Despu√©s, el nodo `If Max Retry` comprueba si se ha alcanzado el l√≠mite de 3 reintentos. Si no se ha alcanzado, el flujo vuelve al `AI Agent2` para que genere un nuevo an√°lisis. Si se alcanza el l√≠mite, el flujo termina en un error.

#### Paso 3: La Fusi√≥n de Ramas

La rama "True" del nodo `If1` se conecta directamente al nodo final de formateo, `Code in JavaScript5`.

---
### Formateo Final y Respuesta al Usuario

#### `Code in JavaScript5` (Formateador Avanzado)

Este es el nodo de c√≥digo que prepara la respuesta final. Su trabajo es tomar el an√°lisis *final y aprobado* y convertirlo en el mensaje que ver√° el usuario. Su l√≥gica interna hace lo siguiente:

1.  **Extracci√≥n con Regex:** Toma el `aiResponse` (el texto del an√°lisis correcto del `AI Agent2`) y utiliza **Expresiones Regulares (`.match()`)** para extraer los valores de cada l√≠nea (ej: `Compra: (\d+)%`).
2.  **Formateo HTML:** Finalmente, construye el mensaje de respuesta usando **etiquetas HTML** (como `<b>` para negrita) para darle estilo, incluyendo emojis (`üìà` o `üìâ`) seg√∫n la expectativa.

#### `Send a text message1` (Env√≠o por Telegram)

Este es el √∫ltimo nodo. Recibe el `responseText` (el texto HTML) del nodo anterior y lo env√≠a al usuario. La configuraci√≥n clave aqu√≠ es:
* **`Chat ID`:** Se obtiene din√°micamente del *primer* nodo del flujo (`Telegram Trigger`), asegurando que la respuesta siempre vuelva al usuario que hizo la petici√≥n.
* **`Parse Mode`:** Se establece en **`HTML`** para que Telegram interprete correctamente las etiquetas `<b>` y `‚Ä¢` que hemos definido.

Este ciclo completo asegura que el usuario reciba una respuesta no solo r√°pida, sino tambi√©n verificada, fiable y formateada profesionalmente.